{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jWcOC5hllYde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525198c5-69f8-402c-b944-b6b7c668d0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "def preprocess_images(images, target_size=(28, 28)):\n",
        "    # Add a channel dimension if needed (for grayscale images)\n",
        "    images = images[..., tf.newaxis]\n",
        "\n",
        "    # Resize images\n",
        "    images_resized = tf.image.resize(images, target_size)\n",
        "\n",
        "    # Normalize the images\n",
        "    images_normalized = images_resized / 255.0\n",
        "\n",
        "    return images_normalized.numpy()\n",
        "\n",
        "# Resize and preprocess the images\n",
        "x_train_preprocessed = preprocess_images(x_train)\n",
        "x_test_preprocessed = preprocess_images(x_test)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "def train_model(model, x_train_preprocessed, y_train, epochs=10, optimizer = 'adam'):\n",
        "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(x_train_preprocessed, y_train, epochs=epochs, batch_size=128, validation_split=0.2) # Use x_train_preprocessed here\n",
        "\n",
        "def test_model(model, x_test_preprocessed, y_test):\n",
        "    test_loss, test_accuracy = model.evaluate(x_test_preprocessed, y_test) # Use x_test_preprocessed here\n",
        "    print(f'Test accuracy: {test_accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "train_model(model1, x_train_preprocessed, y_train, 10)\n",
        "test_model(model1, x_test_preprocessed, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2-aZkH0C8DL",
        "outputId": "29028c2f-b4bc-484f-fd69-eece78f8f222"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 15s 14ms/step - loss: 0.3643 - accuracy: 0.8871 - val_loss: 2.9969 - val_accuracy: 0.2258\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0972 - accuracy: 0.9696 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0743 - accuracy: 0.9774 - val_loss: 0.0319 - val_accuracy: 0.9904\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 0.0326 - val_accuracy: 0.9904\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.0331 - val_accuracy: 0.9905\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0481 - accuracy: 0.9850 - val_loss: 0.0344 - val_accuracy: 0.9913\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.0410 - accuracy: 0.9882 - val_loss: 0.0285 - val_accuracy: 0.9919\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0363 - accuracy: 0.9886 - val_loss: 0.0272 - val_accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0284 - val_accuracy: 0.9920\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.0247 - val_accuracy: 0.9925\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9933\n",
            "Test accuracy: 0.9933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = models.Sequential()\n",
        "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(64, activation='relu'))\n",
        "model2.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "train_model(model2, x_train_preprocessed, y_train, 10, 'rmsprop')\n",
        "test_model(model2, x_test_preprocessed, y_test)"
      ],
      "metadata": {
        "id": "7fOYNN7K5wca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6aead9-31ae-4781-8170-f1e702e9a957"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 0.2907 - accuracy: 0.9103 - val_loss: 0.0812 - val_accuracy: 0.9766\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 0.0574 - val_accuracy: 0.9837\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.0475 - val_accuracy: 0.9863\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 0.0420 - val_accuracy: 0.9877\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.0402 - val_accuracy: 0.9892\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0365 - val_accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.0455 - val_accuracy: 0.9889\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0402 - val_accuracy: 0.9898\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0433 - val_accuracy: 0.9887\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0473 - val_accuracy: 0.9897\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9910\n",
            "Test accuracy: 0.9910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Flatten(input_shape=(28, 28, 1)))\n",
        "model3.add(Dense(units=128, activation='relu'))\n",
        "model3.add(Dense(units=128, activation='relu'))\n",
        "model3.add(Dropout(0.25))\n",
        "model3.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "train_model(model3, x_train_preprocessed, y_train, 10)\n",
        "test_model(model3, x_test_preprocessed, y_test)"
      ],
      "metadata": {
        "id": "rW6B7UpsBAOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede03b40-6369-4211-81fd-f5614223b25d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 3s 4ms/step - loss: 0.4179 - accuracy: 0.8745 - val_loss: 0.1766 - val_accuracy: 0.9492\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1663 - accuracy: 0.9506 - val_loss: 0.1241 - val_accuracy: 0.9625\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1165 - accuracy: 0.9643 - val_loss: 0.1061 - val_accuracy: 0.9694\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9737 - val_loss: 0.0939 - val_accuracy: 0.9714\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.9781 - val_loss: 0.0869 - val_accuracy: 0.9731\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.0907 - val_accuracy: 0.9726\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9853 - val_loss: 0.0794 - val_accuracy: 0.9772\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0814 - val_accuracy: 0.9769\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: 0.0861 - val_accuracy: 0.9762\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.0871 - val_accuracy: 0.9759\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9773\n",
            "Test accuracy: 0.9773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import PureWindowsPath\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(28,28), color_mode='grayscale')\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = img_array / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array, img\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "path = '/content/drive/My Drive/image.jpg'\n",
        "img_path = path\n",
        "\n",
        "new_test_image, img = preprocess_image(img_path)\n",
        "\n",
        "# Display the preprocessed image in grayscale\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.title('Preprocessed Grayscale Image')\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "prediction1 = model1.predict(new_test_image)\n",
        "prediction2 = model2.predict(new_test_image)\n",
        "prediction3 = model3.predict(new_test_image)\n",
        "\n",
        "predicted_digit1 = np.argmax(prediction1, axis=1)[0]\n",
        "predicted_digit2 = np.argmax(prediction2, axis=1)[0]\n",
        "predicted_digit3 = np.argmax(prediction3, axis=1)[0]\n",
        "\n",
        "print('Model 1 prediction:', predicted_digit1)\n",
        "print('Model 2 prediction:', predicted_digit2)\n",
        "print('Model prediction:', predicted_digit3)\n",
        "\n",
        "votes = [predicted_digit1, predicted_digit2, predicted_digit3]\n",
        "vote_counts = Counter(votes)\n",
        "predicted_digit, count = vote_counts.most_common(1)[0]\n",
        "\n",
        "print(f'The model predicts this image is the digit: {predicted_digit}')"
      ],
      "metadata": {
        "id": "OLTfJspEJPdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "e63568fc-cf1f-44b3-81fb-78df118c5076"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "Model 1 prediction: 6\n",
            "Model 2 prediction: 6\n",
            "Model prediction: 6\n",
            "The model predicts this image is the digit: 6\n"
          ]
        }
      ]
    }
  ]
}